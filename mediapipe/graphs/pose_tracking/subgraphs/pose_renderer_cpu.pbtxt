# MediaPipe pose landmarks rendering subgraph.

type: "PoseRendererCpu"

# CPU image. (ImageFrame)
input_stream: "IMAGE:input_image"
# Pose landmarks. (NormalizedLandmarkList)
#input_stream: "LANDMARKS:pose_landmarks"
# Segmentation mask. (ImageFrame in ImageFormat::VEC32F1)
input_stream: "SEGMENTATION_MASK:segmentation_mask"
# Region of interest calculated based on landmarks. (NormalizedRect)
input_stream: "ROI:roi"
# Detected pose. (Detection)
input_stream: "DETECTION:detection"

# CPU image with rendered data. (ImageFrame)
output_stream: "IMAGE:output_image"

node {
  calculator: "ImagePropertiesCalculator"
  input_stream: "IMAGE:input_image"
  output_stream: "SIZE:image_size"
}


node {
  calculator: "VirtualBackgroundCalculator"
  input_stream: "IMAGE:input_image"
  input_stream: "MASK:segmentation_mask"
  output_stream: "IMAGE:segmented_image"
  node_options: {
    [type.googleapis.com/mediapipe.VirtualBackgroundCalculatorOptions] {
      mask_channel: RED
      invert_mask: true
      adjust_with_luminance: false
      background_image_path:"D:\\workspace\\OpenSource\\mediapipe.git\\test_file\\virtual_background\\1 (3).jpg"
    }
  }
}



# Draws annotations and overlays them on top of the input images.
node {
  calculator: "AnnotationOverlayCalculator"
  input_stream: "IMAGE:segmented_image"
#  input_stream: "detection_render_data"
#  input_stream: "VECTOR:landmarks_render_data"
#  input_stream: "roi_render_data"
  output_stream: "IMAGE:output_image"
}
